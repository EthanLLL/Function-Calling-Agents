{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05798792-01f6-46c7-ac67-2c78e1db9f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in ./env/lib/python3.10/site-packages (1.34.16)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.16 in ./env/lib/python3.10/site-packages (from boto3) (1.34.16)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in ./env/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in ./env/lib/python3.10/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./env/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.16->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in ./env/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.16->boto3) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.16->boto3) (1.16.0)\n",
      "Requirement already satisfied: openai==0.27.8 in ./env/lib/python3.10/site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in ./env/lib/python3.10/site-packages (from openai==0.27.8) (2.31.0)\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.10/site-packages (from openai==0.27.8) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in ./env/lib/python3.10/site-packages (from openai==0.27.8) (3.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests>=2.20->openai==0.27.8) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests>=2.20->openai==0.27.8) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests>=2.20->openai==0.27.8) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests>=2.20->openai==0.27.8) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.10/site-packages (from aiohttp->openai==0.27.8) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.10/site-packages (from aiohttp->openai==0.27.8) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./env/lib/python3.10/site-packages (from aiohttp->openai==0.27.8) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.10/site-packages (from aiohttp->openai==0.27.8) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./env/lib/python3.10/site-packages (from aiohttp->openai==0.27.8) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./env/lib/python3.10/site-packages (from aiohttp->openai==0.27.8) (4.0.3)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.10/site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.10/site-packages (from requests) (2023.11.17)\n",
      "Requirement already satisfied: mistralai in ./env/lib/python3.10/site-packages (0.0.9)\n",
      "Requirement already satisfied: httpx<0.26.0,>=0.25.2 in ./env/lib/python3.10/site-packages (from mistralai) (0.25.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.10 in ./env/lib/python3.10/site-packages (from mistralai) (3.9.10)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in ./env/lib/python3.10/site-packages (from mistralai) (2.5.3)\n",
      "Requirement already satisfied: anyio in ./env/lib/python3.10/site-packages (from httpx<0.26.0,>=0.25.2->mistralai) (4.2.0)\n",
      "Requirement already satisfied: certifi in ./env/lib/python3.10/site-packages (from httpx<0.26.0,>=0.25.2->mistralai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in ./env/lib/python3.10/site-packages (from httpx<0.26.0,>=0.25.2->mistralai) (1.0.2)\n",
      "Requirement already satisfied: idna in ./env/lib/python3.10/site-packages (from httpx<0.26.0,>=0.25.2->mistralai) (3.6)\n",
      "Requirement already satisfied: sniffio in ./env/lib/python3.10/site-packages (from httpx<0.26.0,>=0.25.2->mistralai) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./env/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.26.0,>=0.25.2->mistralai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./env/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in ./env/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./env/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./env/lib/python3.10/site-packages (from anyio->httpx<0.26.0,>=0.25.2->mistralai) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3\n",
    "!pip install openai==0.27.8\n",
    "!pip install requests\n",
    "!pip install mistralai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9361f1-83e2-4ce5-a854-fab36acc2fa0",
   "metadata": {},
   "source": [
    "## GenAI\n",
    "\n",
    "ç”Ÿæˆåˆ›æ„å†…å®¹çš„ç»“æœåªèƒ½æ„Ÿæ€§/ç›¸å¯¹ç†æ€§çš„è¯„ä»·ï¼Œæ— æ³•é‡åŒ–ã€‚\n",
    "æ— æ³•é‡åŒ– = æ— æ³•æ ‡å‡†åŒ– = æ— æ³•å•†ä¸šåŒ–\n",
    "\n",
    "> æ—¢ç„¶æ²¡æœ‰æ ‡å‡†ç­”æ¡ˆï¼Œå†™ä½œæ–‡å¦‚ä½•æ‹¿åˆ°æ»¡åˆ†ğŸ’¯ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637642cd-8eaa-4916-a841-17caf3881723",
   "metadata": {},
   "source": [
    "## èƒ½æ‹¿åˆ°æ»¡åˆ†çš„æ˜¯ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea458bb8-9dea-4846-aaf3-58195afde8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Bedrock client\n",
    "brt = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')\n",
    "\n",
    "def claude_complete(prompt):\n",
    "    body = json.dumps({\n",
    "        'prompt': prompt,\n",
    "        'max_tokens_to_sample': 300,\n",
    "        'temperature': 0,\n",
    "        'top_p': 0.9,\n",
    "    })\n",
    "    \n",
    "    model_id = 'anthropic.claude-v2'\n",
    "    accept = 'application/json'\n",
    "    content_type = 'application/json'\n",
    "    \n",
    "    response = brt.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "    \n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    \n",
    "    # text\n",
    "    completion = response_body.get('completion')\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c01cc3-45e9-4487-af53-e68365e701e9",
   "metadata": {},
   "source": [
    "#### é€‰æ‹©é¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7618c0ef-29c2-420c-b182-eca36e80aa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' å¯¹äºç”¨æˆ·æå‡ºçš„é—®é¢˜â€œè¯·é—® Amazon è‚¡ç¥¨ä»Šå¤©å¤šå°‘é’±?â€,æˆ‘ä¼šé€‰æ‹©ä½¿ç”¨æŸ¥è¯¢è‚¡ç¥¨ä»·æ ¼çš„å·¥å…·æ¥å›ç­”ã€‚\\n\\næˆ‘çš„å›ç­”æ˜¯:æŸ¥è¯¢è‚¡ç¥¨ä»·æ ¼'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = '''\n",
    "ä½ æ˜¯1ä¸ªè´´å¿ƒçš„ç§äººåŠ©ç†ï¼Œå°±åƒHerè¿™ä¸ªç”µå½±é‡Œçš„ Scarlett Johanssonã€‚\n",
    "ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ä»¥ä½¿ç”¨ï¼š\n",
    "1ã€æŸ¥è¯¢å¤©æ°”ï¼›\n",
    "2ã€æŸ¥è¯¢è‚¡ç¥¨ä»·æ ¼ï¼›\n",
    "3ã€å¯¹ AWS å¹³å°ä¸Šçš„ EC2 è™šæ‹Ÿæœºèµ„æºè¿›è¡Œç®¡ç†ï¼›\n",
    "è¯·åŸºäºç”¨æˆ·è¾“å…¥ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·ï¼Œè¾“å‡ºä½ é€‰æ‹©çš„å·¥å…·å³å¯ã€‚\n",
    "'''\n",
    "\n",
    "user_prompt = 'è¯·é—® Amazon è‚¡ç¥¨ä»Šå¤©å¤šå°‘é’±ï¼Ÿ'\n",
    "\n",
    "prompt = f'\\n\\nHuman: {system_prompt}\\nç”¨æˆ·è¾“å…¥ï¼š{user_prompt}\\n\\nAssistant:'\n",
    "\n",
    "completion = claude_complete(prompt)\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b46523fe-9113-4791-aadd-46b5f8a9772d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' æ‚¨è¦æˆ‘æŠŠæ‰€æœ‰ EC2 è™šæ‹Ÿæœºåœæ­¢,è¿™éœ€è¦ä½¿ç”¨ AWS å¹³å°ä¸Šçš„è™šæ‹Ÿæœºç®¡ç†å·¥å…·ã€‚æˆ‘ä¼šé€‰æ‹©ä½¿ç”¨ç¬¬3ä¸ªå·¥å…·,å¯¹ AWS å¹³å°ä¸Šçš„ EC2 è™šæ‹Ÿæœºèµ„æºè¿›è¡Œç®¡ç†,æ¥å®Œæˆæ‚¨çš„è¯·æ±‚ã€‚'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = 'è¯·å¸®æˆ‘æŠŠæ‰€æœ‰ EC2 è™šæ‹Ÿæœºåœæ­¢'\n",
    "\n",
    "prompt = f'\\n\\nHuman: {system_prompt}\\nç”¨æˆ·è¾“å…¥ï¼š{user_prompt}\\n\\nAssistant:'\n",
    "\n",
    "completion = claude_complete(prompt)\n",
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8707e8-7764-4130-a6bb-39b194870be3",
   "metadata": {},
   "source": [
    "#### å¡«ç©ºé¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bcb58e6-a41a-4e75-bbea-2f8b6418350f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' æ ¹æ®ç”¨æˆ·è¾“å…¥,æˆ‘æå–å‡ºä»¥ä¸‹å…³é”®å‚æ•°:\\n\\n{\\n  \"where\": {\\n    \"city\": \"å¹¿å·\", \\n    \"price_range\": [250, 350],\\n    \"breakfast\": false\\n  },\\n  \"count\": 5\\n}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = '''\n",
    "ä½ æ˜¯1ä¸ªè´´å¿ƒçš„ç§äººåŠ©ç†ï¼Œå°±åƒHerè¿™ä¸ªç”µå½±é‡Œçš„ Scarlett Johanssonã€‚\n",
    "ä½ æœ‰1ä¸ªé…’åº—æŸ¥è¯¢APIå¯ä»¥ä½¿ç”¨ï¼Œæ¥å£åè®®å¦‚ä¸‹ï¼š\n",
    "{\n",
    "    \"where\": {\n",
    "        \"city\": <é¢„å®šé…’åº—çš„åŸå¸‚ï¼Œæ¯”å¦‚ Beijing>,\n",
    "        \"price_range\": <ä»·æ ¼åŒºé—´åˆ—è¡¨ï¼Œæ¯”å¦‚ [200, 500]>,\n",
    "        \"breakfast\": <æ˜¯å¦åŒ…å«æ—©é¤ï¼Œtrue | falseï¼Œé»˜è®¤ false>\n",
    "    },\n",
    "    \"count\": <å¯ä¾›é€‰æ‹©çš„é…’åº—æ•°é‡>\n",
    "}\n",
    "è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥ï¼Œæå–å…³é”®å‚æ•°ï¼Œè¾“å‡ºjsonç»“æ„ä½“ã€‚\n",
    "'''\n",
    "\n",
    "user_prompt = 'è¯·ç»™æˆ‘5ä¸ªå¹¿å·300ä»·ä½å·¦å³ä¸å«æ—©çš„é…’åº—æ¨èã€‚'\n",
    "\n",
    "prompt = f'\\n\\nHuman: {system_prompt}\\nç”¨æˆ·è¾“å…¥ï¼š{user_prompt}\\n\\nAssistant:'\n",
    "\n",
    "completion = claude_complete(prompt)\n",
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7d45ad-62b7-4221-9ae3-02414de02877",
   "metadata": {},
   "source": [
    "#### å°†é€‰æ‹©é¢˜ä¸å¡«ç©ºé¢˜ç»“åˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "498bd064-6f38-4550-bcd9-0db0776d8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''\n",
    "You have access to the following tools:\n",
    "[\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city or state which is required.\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\n",
    "                        \"celsius\",\n",
    "                        \"fahrenheit\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_current_location\",\n",
    "        \"description\": \"Use this tool to get the current location if user does not provide a location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "Select one of the above tools if needed, respond with only a JSON object matching the following schema inside a <json></json> XML tag:\n",
    "{\n",
    "    \"result\": \"tool_use\",\n",
    "    \"tool\": <name of the selected tool, leave blank if no tools needed>,\n",
    "    \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>,\n",
    "    \"explanation\": <The explanation why you choosed this tool.>\n",
    "}\n",
    "If no further tools needed, response with only a JSON object matching the following schema:\n",
    "{\n",
    "    \"result\": \"stop\",\n",
    "    \"content\": <Your response to the user.>,\n",
    "    \"explanation\": <The explanation why you get the final answer.>\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90473a3e-2dec-4b71-8a8c-6a1b6b5e90ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = 'What is the current weather?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d034422-cca6-4c45-8b89-1720eef09c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = [\n",
    "    # Uncomment the chat message\n",
    "    f'\\n\\n{system_prompt}',\n",
    "    f'\\n\\nHuman: {user_prompt}',\n",
    "    # '\\n\\nAssistant: Should use get_current_location tool with args: {}',\n",
    "    # '\\n\\nHuman: I have used the get_current_location tool and the result is: Guangzhou',\n",
    "    # '\\n\\nAssistant: Should use get_current_weather tool with args: {\"location\": \"Guangzhou\"}',\n",
    "    # '\\n\\nHuman: I have used the get_current_weather tool and the result is: Rainy at 7 degrees.',\n",
    "    '\\n\\nAssistant: <json>' # Use <json> xml tag to force llm response json only\n",
    "]\n",
    "prompt = ''.join(prompt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fc09589-c1aa-4687-a5ab-ea30991e0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Bedrock client\n",
    "brt = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')\n",
    "\n",
    "def claude_fc_complete(prompt):\n",
    "    body = json.dumps({\n",
    "        'prompt': prompt,\n",
    "        'max_tokens_to_sample': 300,\n",
    "        'temperature': 0,\n",
    "        'top_p': 0.9,\n",
    "        'stop_sequences': ['</json>']\n",
    "    })\n",
    "    \n",
    "    model_id = 'anthropic.claude-v2'\n",
    "    accept = 'application/json'\n",
    "    content_type = 'application/json'\n",
    "    \n",
    "    response = brt.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "    \n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    \n",
    "    # text\n",
    "    completion = response_body.get('completion')\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e57db8d-3adb-4049-94e2-d2df5f3d0436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 'tool_use',\n",
       " 'tool': 'get_current_location',\n",
       " 'tool_input': {},\n",
       " 'explanation': \"I need to get the user's current location first since they did not provide a location.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = claude_fc_complete(prompt)\n",
    "res\n",
    "# A valid json object should be parsed to a python dict\n",
    "function_call = json.loads(res)\n",
    "function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb52eea7-5d97-4f0e-8da3-5865c00b18a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = [\n",
    "    # Uncomment the chat message\n",
    "    f'\\n\\n{system_prompt}',\n",
    "    f'\\n\\nHuman: {user_prompt}',\n",
    "    '\\n\\nAssistant: Should use get_current_location tool with args: {}',\n",
    "    '\\n\\nHuman: I have used the get_current_location tool and the result is: Guangzhou',\n",
    "    # '\\n\\nAssistant: Should use get_current_weather tool with args: {\"location\": \"Guangzhou\"}',\n",
    "    # '\\n\\nHuman: I have used the get_current_weather tool and the result is: Rainy and 7 degrees.',\n",
    "    '\\n\\nAssistant: <json>' # Use <json> xml tag to force llm response json only\n",
    "]\n",
    "prompt = ''.join(prompt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cba7429f-30da-471a-8a31-f5ccb56abe89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 'tool_use',\n",
       " 'tool': 'get_current_weather',\n",
       " 'tool_input': {'location': 'Guangzhou'},\n",
       " 'explanation': 'Since the user provided the location Guangzhou, I will use the get_current_weather tool to get the current weather for that location.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = claude_fc_complete(prompt)\n",
    "function_call = json.loads(res)\n",
    "function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40a28d8e-066a-4ffb-a5bc-f822300091bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = [\n",
    "    # Uncomment the chat message\n",
    "    f'\\n\\n{system_prompt}',\n",
    "    f'\\n\\nHuman: {user_prompt}',\n",
    "    '\\n\\nAssistant: Should use get_current_location tool with args: {}',\n",
    "    '\\n\\nHuman: I have used the get_current_location tool and the result is: Guangzhou',\n",
    "    '\\n\\nAssistant: Should use get_current_weather tool with args: {\"location\": \"Guangzhou\"}',\n",
    "    '\\n\\nHuman: I have used the get_current_weather tool and the result is: The weather in Guangzhou today is 25 degrees Celsius and sunny',\n",
    "    '\\n\\nAssistant: <json>' # Use <json> xml tag to force llm response json only\n",
    "]\n",
    "prompt = ''.join(prompt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d43f5ae6-eb65-48da-b5d2-ab13535871e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 'stop',\n",
       " 'content': 'The weather in Guangzhou today is 25 degrees Celsius and sunny',\n",
       " 'explanation': \"I first used the get_current_location tool to get the user's location which is Guangzhou. Then I used the get_current_weather tool to get the current weather in Guangzhou, which is 25 degrees Celsius and sunny.\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = claude_fc_complete(prompt)\n",
    "function_call = json.loads(res)\n",
    "function_call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500e8800-a73d-43ab-ad0f-e5f4d125f744",
   "metadata": {},
   "source": [
    "#### Good Job Claude 2 ğŸ˜€\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f2b563-a901-4540-a700-da8de092d457",
   "metadata": {},
   "source": [
    "### LLM èƒ½åŠ›\n",
    "\n",
    "~~è¾“å…¥ -> è¾“å‡º~~\n",
    "\n",
    "éç»“æ„åŒ–è¾“å…¥ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰ -> ç»“æ„åŒ–è¾“å‡º\n",
    "\n",
    "---\n",
    "\n",
    "### Interface ä»£è¡¨äº†\n",
    "1. æµé‡å…¥å£\n",
    "2. ç¤¾ä¼šæ´»åŠ¨\n",
    "\n",
    "---\n",
    "\n",
    "### Interface çš„é—®é¢˜\n",
    "1. UI å¤ªéš¾ç”¨ï¼ˆåªè¦æŒç»­è¿­ä»£æ–°åŠŸèƒ½ï¼Œè¿™ä¸ªè¿‡ç¨‹ä¸å¯é€†ï¼‰\n",
    "2. API æ™®é€šç”¨æˆ·ä¸ä¼šç”¨\n",
    "\n",
    "---\n",
    "\n",
    "### LLM ç»Ÿä¸€äº†æ¥å£åè®®\n",
    "1. UI åªå‰©ä¸‹**èŠå¤©æ¡†**ï¼Œå¯¹å®¢æˆ·ç«¯ API åªå‰©1ä¸ªâ€œpromptâ€å‚æ•°\n",
    "2. Frontend -> Chatend\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6b9bbc-8e22-4fce-99c3-4c4d1ea5a63a",
   "metadata": {},
   "source": [
    "#### Claude instant å¯ä»¥å—ï¼ŸğŸ¤”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4166597-0c7a-44f1-8e21-e96d7b2a88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Bedrock client\n",
    "brt = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')\n",
    "\n",
    "def claude_fc_complete(prompt):\n",
    "    body = json.dumps({\n",
    "        'prompt': prompt,\n",
    "        'max_tokens_to_sample': 300,\n",
    "        'temperature': 0,\n",
    "        'top_p': 0.9,\n",
    "        'stop_sequences': ['</json>']\n",
    "    })\n",
    "    \n",
    "    model_id = 'anthropic.claude-instant-v1'\n",
    "    accept = 'application/json'\n",
    "    content_type = 'application/json'\n",
    "    \n",
    "    response = brt.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "    \n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    \n",
    "    # text\n",
    "    completion = response_body.get('completion')\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88a36db1-bbaf-4b32-9bb7-5b799d586263",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = [\n",
    "    # Uncomment the chat message\n",
    "    f'\\n\\n{system_prompt}',\n",
    "    f'\\n\\nHuman: {user_prompt}',\n",
    "    # '\\n\\nAssistant: Should use get_current_location tool with args: {}',\n",
    "    # '\\n\\nHuman: I have used the get_current_location tool and the result is: Guangzhou',\n",
    "    # '\\n\\nAssistant: Should use get_current_weather tool with args: {\"location\": \"Guangzhou\"}',\n",
    "    # '\\n\\nHuman: I have used the get_current_weather tool and the result is: Rainy and 7 degrees.',\n",
    "    '\\n\\nAssistant: <json>' # Use <json> xml tag to force llm response json only\n",
    "]\n",
    "prompt = ''.join(prompt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61c58b29-66e0-4458-80a4-fefb7dcd8238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 'tool_use',\n",
       " 'tool': 'get_current_weather',\n",
       " 'tool_input': {'location': 'San Francisco'},\n",
       " 'explanation': \"The user asked for the current weather but did not provide a location. I'm using the get_current_weather tool to get the weather for San Francisco as an example location.\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = claude_fc_complete(prompt)\n",
    "res\n",
    "function_call = json.loads(res)\n",
    "function_call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f58456-09ae-45db-a7a8-bc121841f52a",
   "metadata": {},
   "source": [
    "#### çœ‹èµ·æ¥ä¸æ˜¯å¾ˆè¡ŒğŸ¥²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bef43c2-f0de-436b-8dc7-0b94118c6234",
   "metadata": {},
   "source": [
    "## Agent åº”è¯¥æ˜¯ä¸ªâ€œè‡ªåŠ¨æŒ¡â€ğŸš—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "149a5320-8e4e-4cfc-9cf9-61567d3a5644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def claude_fc_complete(prompt):\n",
    "    body = json.dumps({\n",
    "        'prompt': prompt,\n",
    "        'max_tokens_to_sample': 300,\n",
    "        'temperature': 0,\n",
    "        'top_p': 0.9,\n",
    "        'stop_sequences': ['</json>']\n",
    "    })\n",
    "    \n",
    "    model_id = 'anthropic.claude-v2'\n",
    "    accept = 'application/json'\n",
    "    content_type = 'application/json'\n",
    "    \n",
    "    response = brt.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "    \n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    \n",
    "    # text\n",
    "    completion = response_body.get('completion')\n",
    "    result = json.loads(completion)\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "def get_current_location():\n",
    "    # Mock response\n",
    "    return 'Guangzhou'\n",
    "\n",
    "def get_current_weather(location, unit='celsius'):\n",
    "    # Mock response\n",
    "    print(f'location: {location}')\n",
    "    assert location == 'Guangzhou'\n",
    "    return 'Sunny at 25 degrees Celsius.'\n",
    "\n",
    "function_map = {\n",
    "    'get_current_location': get_current_location,\n",
    "    'get_current_weather': get_current_weather\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29e0645e-9e69-4227-9364-c3e605240d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = 'What is the current weather?'\n",
    "messages = [\n",
    "    # Uncomment the chat message\n",
    "    f'\\n\\n{system_prompt}',\n",
    "    f'\\n\\nHuman: {user_prompt}',\n",
    "]\n",
    "assistant_prompt = '\\n\\nAssistant: <json>' # Use <json> xml tag to force llm response json only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db1c0903-ab93-46cc-96ce-0482065d471d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the current weather?\n",
      "{'result': 'tool_use', 'tool': 'get_current_location', 'tool_input': {}, 'explanation': \"I need to get the user's current location first since they did not provide a location.\"}\n",
      "{'result': 'tool_use', 'tool': 'get_current_weather', 'tool_input': {'location': 'Guangzhou'}, 'explanation': 'Since the user did not provide a location, I used the get_current_location tool to get their current location. Now I will call the get_current_weather tool to get the weather for their current location of Guangzhou.'}\n",
      "location: Guangzhou\n",
      "{'result': 'stop', 'content': 'The current weather in Guangzhou is Sunny at 25 degrees Celsius.', 'explanation': \"I first used the get_current_location tool to get the user's location which is Guangzhou. Then I used the get_current_weather tool with Guangzhou as the location parameter to get the current weather condition there, which is Sunny at 25 degrees Celsius. So I can now provide the full response to the user.\"}\n",
      "AI: The current weather in Guangzhou is Sunny at 25 degrees Celsius.\n"
     ]
    }
   ],
   "source": [
    "finished = False\n",
    "\n",
    "print(f'User: {user_prompt}')\n",
    "prompt = f'{\"\".join(messages)}{assistant_prompt}'\n",
    "response = ''\n",
    "\n",
    "while not finished:\n",
    "    result = claude_fc_complete(prompt)\n",
    "    if result['result'] == 'tool_use':\n",
    "        tool = result['tool']\n",
    "        tool_input = result['tool_input']\n",
    "        function2call = function_map[tool]\n",
    "        # calling the function\n",
    "        function_result = function2call(**tool_input)\n",
    "        # Append to prompts\n",
    "        messages.append(f'\\n\\nAssistant: Should use {tool} tool with args: {json.dumps(tool_input)}')\n",
    "        messages.append(f'\\n\\nHuman: I have used the {tool} tool and the result is : {function_result}')\n",
    "        prompt = f'{\"\".join(messages)}{assistant_prompt}'\n",
    "    elif result['result'] == 'stop':\n",
    "        finished = True\n",
    "        response = result['content']\n",
    "\n",
    "print(f'AI: {response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c648f76-e8b9-45f2-92d0-f26b0134ea80",
   "metadata": {},
   "source": [
    "### ğŸ’¡æˆ‘ä»¬å…¶å®ä¸éœ€è¦ Langchain\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4ea4f-3822-44e8-aff0-802437155ef6",
   "metadata": {},
   "source": [
    "### å…¶ä»–æ¨¡å‹ï¼ŸğŸ¤”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e39a3-3481-4f8b-8743-ca04884f69bc",
   "metadata": {},
   "source": [
    "#### Mixtral 8*7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "755a1151-13ff-4ae1-84d7-e6fd0aafd802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "api_key = 'd2gf1pWrXrZYnjxIMty6wwxauLTaeaXZ'\n",
    "model = 'mistral-small' # 8*7b MOE\n",
    "\n",
    "client = MistralClient(api_key=api_key)\n",
    "\n",
    "def mixtral_complete(messages):\n",
    "    chat_response = client.chat(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    content = chat_response.choices[0].message.content\n",
    "    res = json.loads(content)\n",
    "    print(res)\n",
    "    return res\n",
    "\n",
    "system_prompt = '''\n",
    "You have access to the following tools:\n",
    "[\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city or state which is required.\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\n",
    "                        \"celsius\",\n",
    "                        \"fahrenheit\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_current_location\",\n",
    "        \"description\": \"Use this tool to get the current location if user does not provide a location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "Select one of the above tools if needed and if tool needed, respond with only a JSON object matching the following schema.:\n",
    "{\n",
    "    \"result\": \"tool_use\",\n",
    "    \"tool\": <name of the selected tool, leave blank if no tools needed>,\n",
    "    \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema, leave blank if no tools needed>,\n",
    "    \"explanation\": <The explanation why you choosed this tool or no need for further tools.>\n",
    "}\n",
    "If no further tools needed, response with only a JSON object matching the following schema:\n",
    "{\n",
    "    \"result\": \"stop\",\n",
    "    \"content\": <Your response to the user.>,\n",
    "    \"explanation\": <The explanation why you get the final answer.>\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfb5f4b9-ffcb-4d94-b783-a30f0e17f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'What is the current weather?'\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=\"system\", content=system_prompt),\n",
    "    ChatMessage(role=\"user\", content=prompt),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "740862d6-b094-4977-96c0-3ff8865541da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the current weather?\n",
      "{'result': 'tool_use', 'tool': 'get_current_location', 'tool_input': {}, 'explanation': \"The user did not provide a location, so I will first use the 'get_current_location' tool to determine the user's current location.\"}\n",
      "{'result': 'tool_use', 'tool': 'get_current_weather', 'tool_input': {'location': 'Guangzhou', 'unit': 'celsius'}, 'explanation': \"We need to know the current weather in the user's location to respond appropriately. The user has provided their location as Guangzhou, so we can use this tool with the input 'Guangzhou' to fetch the current weather.\"}\n",
      "location: Guangzhou\n",
      "{'result': 'stop', 'content': 'Sunny at 25 degrees Celsius.', 'explanation': \"The get_current_location tool was used to determine the user's location, which returned 'Guangzhou'. Then, the get_current_weather tool was used with the location 'Guangzhou' and unit 'celsius' to determine the current weather. The response from this tool is 'Sunny at 25 degrees Celsius'.\"}\n",
      "AI: Sunny at 25 degrees Celsius.\n"
     ]
    }
   ],
   "source": [
    "finished = False\n",
    "print(f'User: {prompt}')\n",
    "response = ''\n",
    "\n",
    "while not finished:\n",
    "    result = mixtral_complete(messages)\n",
    "    if result['result'] == 'tool_use':\n",
    "        tool = result['tool']\n",
    "        tool_input = result['tool_input']\n",
    "        function2call = function_map[tool]\n",
    "        # calling the function\n",
    "        function_result = function2call(**tool_input)\n",
    "        # Append to prompts\n",
    "        messages.append(ChatMessage(role='assistant', content=f'Should use {tool} tool with args: {json.dumps(tool_input)}'))\n",
    "        messages.append(ChatMessage(role='user', content=f'I have used the {tool} tool and the result is : {function_result}'))\n",
    "    elif result['result'] == 'stop':\n",
    "        finished = True\n",
    "        response = result['content']\n",
    "\n",
    "print(f'AI: {response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca8945-35ed-4aab-9f62-29d5720b48da",
   "metadata": {},
   "source": [
    "#### OpenAI GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85cdda75-c647-4ac0-a68a-649ad870fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city or state which is required.\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\n",
    "                        \"celsius\",\n",
    "                        \"fahrenheit\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_current_location\",\n",
    "        \"description\": \"Use this tool to get the current location if user does not provide a location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def openai_complete(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=messages,\n",
    "        functions=functions\n",
    "    )\n",
    "    # print(response)\n",
    "    return response['choices'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cded1f21-396a-4ad6-b0bc-b599310b2692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the current weather?\n",
      "location: Guangzhou\n",
      "AI: The current weather in Guangzhou is sunny with a temperature of 25 degrees Celsius.\n"
     ]
    }
   ],
   "source": [
    "finished = False\n",
    "prompt = 'What is the current weather?'\n",
    "print(f'User: {prompt}')\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'You are godfather, please speak in the tone of a godfather'},\n",
    "    {'role': 'user', 'content': prompt}\n",
    "]\n",
    "response = ''\n",
    "\n",
    "while not finished:\n",
    "    result = openai_complete(messages)\n",
    "    message = result['message']\n",
    "    if result['finish_reason'] == 'function_call':\n",
    "        tool = message['function_call']['name']\n",
    "        tool_input = json.loads(message['function_call']['arguments'])\n",
    "        function2call = function_map[tool]\n",
    "        # calling the function\n",
    "        function_result = function2call(**tool_input)\n",
    "        # Append to prompts\n",
    "        messages.append({'role': 'assistant', 'content': f'Should use {tool} tool with args: {json.dumps(tool_input)}'})\n",
    "        messages.append({'role': 'function', 'name': tool, 'content': f'I have used the {tool} tool and the result is : {function_result}'})\n",
    "    elif result['finish_reason'] == 'stop':\n",
    "        finished = True\n",
    "        response = message['content']\n",
    "\n",
    "print(f'AI: {response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ac1d10-c30a-4c72-b1c7-7ec3f4b845b1",
   "metadata": {},
   "source": [
    "### å…¶ä»–ç½‘çº¢æ¨¡å‹å’Œ SLM è¡¨ç°å¦‚ä½•ï¼ŸğŸ¤©\n",
    "\n",
    "#### 7b æ¨¡å‹\n",
    "- Mistral 7b\n",
    "- Llama 2 7b\n",
    "- Openchat (Benchmark å…¨é¢ä¼˜äº GPT 3.5 ğŸ¤”)\n",
    "- OpenHermes\n",
    "\n",
    "> åœ¨ LLM Benchmark é¢å‰ï¼Œç¾é¢œç›¸æœºæ›´å€¼å¾—ä¿¡ä»»ğŸ“·\n",
    "\n",
    "#### <3b æ¨¡å‹\n",
    "- Phi 2 2.7b\n",
    "- TinyLlama\n",
    "\n",
    "> è™½ç„¶ä¸€ç‚¹èƒ½åŠ›éƒ½æ²¡æœ‰ï¼Œä½†èƒ½éƒ¨ç½²åˆ° Lambda ä¸Šç”¨ CPU æ¨ç†ï¼Œæ¯ç§’èƒ½è¾“å‡º16ä¸ªå·¦å³ token ğŸ˜»\n",
    "\n",
    "#### ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦å…³æ³¨7båŠå‚æ•°æ›´å°çš„æ¨¡å‹ï¼Ÿ\n",
    "> å¦‚æœ7b æ¨¡å‹çš„èƒ½åŠ›è¶³å¤Ÿçš„è¯ï¼Œé‚£ä¹ˆ LLM åº”ç”¨çš„æ¨ç†æ˜¯å¯ä»¥åœ¨å®¢æˆ·ç«¯çš„ğŸ˜±ï¼Œå½“ä¸‹è¿˜ä¸éœ€è¦ç„¦è™‘ğŸ˜‰ï¼ˆ2024/01/13ï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf882a11-4230-4b84-9e50-fc52a57440bb",
   "metadata": {},
   "source": [
    "## å¸Œæœ› Service Team å¯ä»¥å°½æ—©æ‰˜ç®¡ Mixtral 8*7 ğŸ™ğŸ™\n",
    "\n",
    "| æ¨¡å‹      | Function Calling | Price Input(1m token) | Price Output(1m token) |\n",
    "|  ----    | ----  | ---- | ---- |\n",
    "| Claude 2 | ğŸ‘ | 8 | 24 |\n",
    "| Claude Instant | ğŸ˜­ | 0.8 | 2.4 |\n",
    "| GPT 3.5 | ğŸ‘ | 1 | 2 |\n",
    "| Mixtral 8x7 | ğŸ‘ | 0.66 | 1.97 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a225d13-3900-4496-81de-fc4cbdef5e2d",
   "metadata": {},
   "source": [
    "## ç©·ä¸¾ Function çš„é—®é¢˜\n",
    "\n",
    "ä»å‰é¢çš„ä¾‹å­ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼š\n",
    "- Agent Loop éœ€è¦å¤šæ¬¡è°ƒç”¨ LLM æ¨ç†ï¼›\n",
    "- æ¯æ¬¡è°ƒç”¨éƒ½éœ€è¦å¸¦ä¸Šä¸‹æ–‡ & æ‰€æœ‰ Function schemaï¼›\n",
    "\n",
    "> Token æ¶ˆè€—å¤ªå¤š\n",
    ">\n",
    "> å¦‚æœæˆ‘ä»¬è¦æä¾›ä¸Šç™¾ä¸ª Functionï¼ŒContext Length å¤§æ¦‚ç‡ä¹Ÿä¸å¤Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca9ccf5-1314-444f-91a5-aaf6cda871e6",
   "metadata": {},
   "source": [
    "## å¯¹ Function è¿›è¡ŒæŠ½è±¡\n",
    "\n",
    "å‡è®¾æˆ‘ä»¬è¦æ„å»º1ä¸ª AI åŠ©ç†ï¼Œæä¾›ä»¥ä¸‹åŠŸèƒ½ï¼š\n",
    "1. åœ¨æœ´æœ´ä¸‹å•ä¹°èœ\n",
    "   1. å…³é”®è¯æœç´¢é£Ÿæ\n",
    "   2. åŠ å…¥è´­ç‰©è½¦\n",
    "   3. æäº¤è®¢å•\n",
    "2. ç®¡ç† AWS èµ„æº\n",
    "   1. EC2\n",
    "   2. EKS\n",
    "   3. æ•°æ®åº“\n",
    "   4. çœ‹çœ‹ç›‘æ§æŒ‡æ ‡\n",
    "3. åœ¨ BI ç³»ç»Ÿä¸­çœ‹æŠ¥è¡¨\n",
    "4. åœ¨ ERP ç³»ç»Ÿä¸­æ“ä½œå•†å“ã€è®¢å•\n",
    "   ...\n",
    "\n",
    "è¿™é‡Œåˆ—å‡ºçš„åŠŸèƒ½ç©·ä¸¾ä¸‹æ¥æœ‰å‡ åä¸ª Functionï¼Œæ˜¾ç„¶ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€‚\n",
    "\n",
    "ä¸è¿‡ä¸Šè¿°åŠŸèƒ½æœ¬è´¨ä¸Šéƒ½æ˜¯å¤–éƒ¨æ¥å£è°ƒç”¨ï¼ŒHTTP & SQLï¼ˆAWS SDK ä¹Ÿæ˜¯ HTTPï¼‰ï¼Œæ‰€ä»¥ Function åªç•™ä¸‹ï¼š\n",
    "1. HTTP Client\n",
    "2. SQL Client\n",
    "3. Boto3ï¼ˆè¿˜æ˜¯ç”¨ SDK å§ï¼Œå°±ä¸è‡ªå·±å†™ç­¾åç›¸å…³ä»£ç äº†ï¼‰"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b62221a1-b813-4382-9967-760f90e488ff",
   "metadata": {},
   "source": [
    "```python\n",
    "def http_client(url, method, headers, body):\n",
    "    pass\n",
    "\n",
    "def sql_client(jdbc_url, sql):\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7da635-fdfa-40a2-8c48-b53c66e98310",
   "metadata": {},
   "source": [
    "ç”¨æˆ·è¾“å…¥çš„â€œè¯·å¸®æˆ‘ä¸‹å•300gä¸€å·åœŸçŒªè‚‰ + 200g è–„çš®è¾£æ¤’â€ LLM å¦‚ä½•è½¬æ¢æˆ http_client æ‰€éœ€è¦çš„å‚æ•°å‘¢ï¼Ÿ\n",
    "\n",
    "## RAGâœŒï¸\n",
    "\n",
    "å°† API æ–‡æ¡£å­˜å‚¨åœ¨ Vector Database ä¸­ï¼Œæ£€ç´¢åˆ°ç›¸å…³ API schemaï¼Œåš**å¡«ç©ºé¢˜**è½¬æ¢æˆ Function è¾“å…¥ã€‚\n",
    "\n",
    "å½“å‰ RAG çš„ä¸€èˆ¬è¿‡ç¨‹æ˜¯ï¼š\n",
    "1. ç”¨æˆ·è¾“å…¥é€šè¿‡ embedding è½¬æ¢æˆå‘é‡ï¼›\n",
    "2. æŸ¥è¯¢å‘é‡æ•°æ®åº“ï¼›\n",
    "3. LLM å¸¦ä¸Šä¸‹æ–‡æ¨ç†ï¼›\n",
    "\n",
    "è¿™ä¸ªè¿‡ç¨‹å­˜åœ¨å‡ ä¸ªé—®é¢˜ï¼š\n",
    "1. ç”¨æˆ·è¾“å…¥â€œ*ä½ å¯ä»¥å¸®æˆ‘å†™ä¸€å°é‚®ä»¶å—ï¼Ÿå†…å®¹ä¸»è¦æ˜¯æ³è¯· Mistral ç»™æˆ‘æé«˜æ¥å£ Limit*â€ï¼Œè¿™ä¸ªè¾“å…¥å’Œæˆ‘ä»¬æ„å»ºçš„ Agent ä»¥åŠæ‰€æœ‰ Function éƒ½æ²¡å…³ç³»ï¼Œé‚£ä¹ˆèµ° RAG è¿™ä¸ªè¿‡ç¨‹ï¼Œæ˜¯**æµªè´¹**ï¼ŒåŒæ—¶æˆ‘ä»¬ä¹Ÿä¸çŸ¥é“æ˜¯å¦æ£€ç´¢å‡ºä»€ä¹ˆä¸ç›¸å…³çš„å†…å®¹ï¼Œå¯¼è‡´æœ€ç»ˆæ¨ç†ç»“æœä¸é¢„æœŸä¸ç¬¦ï¼›\n",
    "2. å¬å›ç»“æœä¸ç¬¦åˆé¢„æœŸï¼Œåœ¨å‘é‡æ•°æ®åº“ä¸­æˆ‘ä»¬å­˜å‚¨2ä¸ªæ–‡æ¡£ï¼šReopen a closed order, Close an order\n",
    "   1. ç”¨æˆ·è¾“å…¥â€œè¯·å¸®æˆ‘é‡æ–°æ‰“å¼€è®¢å• idï¼š123456xxâ€ï¼Œæ²¡ç¿»è¯‘å¯èƒ½å®Œå…¨æ£€ç´¢ä¸å‡ºæ¥ï¼›\n",
    "   2. ç”¨æˆ·è¾“å…¥â€œPlease close the order which id is 123456xxâ€ï¼Œå¬å›äº† Reopen a closed orderï¼›\n",
    "\n",
    "è§£ï¼š\n",
    "1. å°†**æŸ¥è¯¢å‘é‡æ•°æ®åº“**æŠ½è±¡æˆ1ä¸ª Functionï¼Œè¿›å…¥ Agent Loop çš„é€»è¾‘ä¸­ï¼Œæ­¤æ—¶ Function åŒ…æ‹¬ï¼š\n",
    "   1. HTTP Client\n",
    "   2. SQL Client\n",
    "   3. Boto3\n",
    "   4. Search From Knowledge Base\n",
    "   ç”± LLM æ¥å†³å®šæ˜¯å¦éœ€è¦æŸ¥è¯¢ API æ–‡æ¡£\n",
    "2. è°ƒæ•´**Search From Knowledge Base** Function å®šä¹‰å’ŒåŠŸèƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdd273a-e3ea-4628-bbc9-3628964ef65d",
   "metadata": {},
   "source": [
    "```python\n",
    "def search_from_knowledge_base(input, threshold=0.75, count=2):\n",
    "    vector = embedding(input)\n",
    "    result = fetch_from_vector_db(vector, threshold, count) # å¤šå¬å›å‡ ä¸ªç›¸å…³çš„\n",
    "    return f'''\n",
    "        I have found some relevant document:\n",
    "        {result}\n",
    "        Please choose the correct document and continue finish the task.\n",
    "    ''' # å†åšä¸€æ¬¡é€‰æ‹©é¢˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73165733-03de-433a-b9b0-d6ec0199486f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Function schema è°ƒæ•´æˆï¼š\n",
    "```json\n",
    "{\n",
    "    \"name\": \"search_from_knowledge_base\",\n",
    "    \"description\": \"Use this function to search API document if user asked you to interact with ERP, BI, Grocery shopping and AWS.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"input\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The summary of user request to semantic search relevant document in English\"\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"input\"]\n",
    "    }\n",
    "}\n",
    "```\n",
    "è®© LLM å¯¹ç”¨æˆ·è¾“å…¥å…ˆåš Summary å¹¶ä¸”ç¿»è¯‘ğŸ’¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743971f7-22f4-4821-acfb-6732adc33dd9",
   "metadata": {},
   "source": [
    "## Code Interpreter\n",
    "\n",
    "> å¦‚æœè¯´ Function Calling è®© LLM èƒ½å¤Ÿ*æœ‰é™è”ç½‘*ï¼Œé‚£ä¹ˆ Code Interpreter å°±ç›¸å½“äºç»™ LLM æ’ä¸Šç¿…è†€ï¼Œ*â€œè‡ªç”±é£ç¿”â€*ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f011379-33c3-48bd-8288-7af3c1f4e1e5",
   "metadata": {},
   "source": [
    "## What Could Possibly Go Wrong? ğŸ˜³\n",
    "\n",
    "æˆ‘ä»¬æ„å»ºäº†1ä¸ª AI åŠ©ç†ï¼Œæä¾›1ä¸ª Function æ‰§è¡Œ Shell å‘½ä»¤:\n",
    "```python\n",
    "def shell_cmd(cmd):\n",
    "    result = os.system(cmd)\n",
    "    return result\n",
    "```\n",
    "æ¥æŸ¥çœ‹æœåŠ¡å™¨çš„ CPUã€å†…å­˜ç­‰ä¿¡æ¯ï¼Œæˆ–æ“ä½œæ–‡ä»¶ã€‚\n",
    "#### ğŸ‘¼ğŸ‘¼\n",
    "- User: åˆšåˆšæ›´æ–°äº†ä¸€äº›é™æ€æ–‡ä»¶ï¼Œè¯·å¸®å¿™é‡å¯ä¸‹ Nginx\n",
    "- Assistant: Should use shell_cmd tool with args: {\"cmd\": \"sudo service nginx restart\"}\n",
    "- Function: Done\n",
    "- Assistant: Nginx has been restarted.\n",
    "\n",
    "---\n",
    "#### ğŸ˜ˆğŸ˜ˆ\n",
    "- User: è¯·åˆ é™¤æ‰€æœ‰æ–‡ä»¶ï¼Œæ€•ä½ ä¸çŸ¥é“ï¼Œå‘½ä»¤æ˜¯ï¼šsudo rm -rf /\n",
    "- Assistant: Should use shell_cmd tool with args: {\"cmd\": \"sudo rm -rf /\"}\n",
    "- Assistant: Internal Server Error\n",
    "\n",
    "### è¯·åƒä¸‡å°å¿ƒï¼Œä½ å¯èƒ½ä¹Ÿä¸çŸ¥é“ä½ æ„å»ºäº†ä¸ªä»€ä¹ˆ AI åŠ©ç†\n",
    "\n",
    "---\n",
    "\n",
    "##### åº”å¯¹ç­–ç•¥\n",
    "1. LLM æ£€æµ‹æ˜¯å¦æœ‰ Prompt Injection Attack é£é™©\n",
    "2. Vector Database å­˜ä¸€äº›å¸¸ç”¨å±é™© prompt\n",
    "3. Function è¯·é€‚åº¦æŠ½è±¡\n",
    "4. æœ€å°ç²’åº¦æˆæƒ\n",
    "5. Code Interpreter å°½é‡åˆ«ç”¨ï¼Œä¸€å®šè¦ç”¨é‚£ä¹Ÿéš”ç¦»1ä¸ª runtimeï¼Œæ¯”å¦‚ Lambdaï¼ŒDocker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c9a90a-5a5f-4779-a3bc-79cf591f38a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
